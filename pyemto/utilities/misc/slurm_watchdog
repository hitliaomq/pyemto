#!/home/hpleva/miniconda2/bin/python

import subprocess

def get_jobs_status(jobids=None, toplevel=True):
    """Returns status of the jobs indicated
    (jobsdict or list of job ids) or all jobs if no jobids supplied.
    Set toplevel=False for job step data.
    
    :param jobids: List of job IDs (Default value = None)
    :type jobids: dict or list
    :param toplevel:  (Default value = True)
    :type toplevel: boolean
    :returns: Job statuses
    :rtype: list(str)
    """
    
    if jobids is None:
        sacct_return = subprocess.Popen(
            'sacct -p -l -S now', shell=True, stdout=subprocess.PIPE).stdout.readlines()
    else:
        if isinstance(jobids, dict):
            qjobs = jobids.keys()
        else:
            qjobs = jobids
        sacct_return = subprocess.Popen(
            'sacct -j %s -p -l' % (
            ','.join(qjobs),), shell=True, stdout=subprocess.PIPE).stdout.readlines()

    jobs_status = {}
    for el in sacct_return[1:]:
        d = dict(
            zip(sacct_return[0].strip().split('|'), el.strip().split('|')))
        if not '.' in d['JobID'] or not toplevel:
            jobs_status[d['JobID']] = d
            
    return jobs_status

def get_status_counts(jobids=None):
    """Returns the counts of all jobs by status category.
    
    :param jobids:  (Default value = None)
    :type jobids:
    :returns: 
    :rtype:
    """
    from collections import defaultdict
    
    jobs_status = get_jobs_status(jobids)
    
    status_counts = defaultdict(int)
    for jd in jobs_status.values():
        status_counts[jd['State'].split()[0]] += 1
    
    return dict(status_counts)

def wait_for_jobs(jobsdict, restart_partition='general', sleeptime=300, restart_z=None,
                  restart_stragglers_after=0.75, kill_if_all_ssusp=False,prn=False,email=False,
                  after_run=None):
    """Loops checking status until no jobs are waiting or running / all are finished.
    
    wait/run states:

    ======= =========== ==================================================================================================
    **Key** **Meaning** **Description**
    ------- ----------- --------------------------------------------------------------------------------------------------
    CF      CONFIGURING Job has been allocated resources, but are waiting for them to become ready for use (e.g. booting).
    CG      COMPLETING  Job is in the process of completing. Some processes on some nodes may still be active.
    PD      PENDING     Job is awaiting resource allocation.
    R       RUNNING     Job currently has an allocation.
    RS      RESIZING    Job is about to change size.
    S       SUSPENDED   Job has an allocation, but execution has been suspended.
    ======= =========== ==================================================================================================

    done states:

    ======= =========== ==============================================================================================================
    **Key** **Meaning** **Description**
    ------- ----------- --------------------------------------------------------------------------------------------------------------
    CA      CANCELLED   Job was explicitly cancelled by the user or system administrator.  The job may or may not have been initiated.
    CD      COMPLETED   Job has terminated all processes on all nodes.
    F       FAILED      Job terminated with non-zero exit code or other failure condition.
    NF      NODE_FAIL   Job terminated due to failure of one or more allocated nodes.
    PR      PREEMPTED   Job terminated due to preemption.
    TO      TIMEOUT     Job terminated upon reaching its time limit.
    ======= =========== ==============================================================================================================

    :param jobsdict:
    :type jobsdict:
    :param restart_partition:  (Default value = 'general')
    :type restart_partition:
    :param sleeptime:  (Default value = 60)
    :type sleeptime:
    :param restart_z:  (Default value = None)
    :type restart_z:
    :param restart_stragglers_after:  (Default value = 0.75)
    :type restart_stragglers_after:
    :param kill_if_all_ssusp:  (Default value = False)
    :type kill_if_all_ssusp:
    :returns: None
    :rtype: None
    """

    run_status = ['CONFIGURING', 'COMPLETING',
                  'PENDING', 'RUNNING', 'RESIZING', 'SUSPENDED']
    done_status = ['CANCELLED', 'COMPLETED',
                   'FAILED', 'NODE_FAIL', 'PREEMPTED', 'TIMEOUT']

    import sys
    import time
    import datetime
    from datetime import datetime as dt_now
    jobs_amount = len(jobsdict)
    if prn == True:
        print()
        print('wait_for_jobs: Submitted {0} jobs'.format(jobs_amount))
    status = get_status_counts(jobsdict)
    t = time.time()
    maxllen = 0

    if prn == True:
        print('wait_for_jobs: Will be requesting job statuses' +
              ' every {0} seconds'.format(sleeptime) + "\n")

    #test_index = 0

    while any([k in run_status for k in status.keys()]): #and test_index < 1:
        time.sleep(sleeptime)
        status = get_status_counts(jobsdict)
        pctdone = sum([status.get(rs, 0)
                       for rs in done_status]) / float(sum(status.values()))

        # CHECK SUSPENDED; RESTART STRAGGLERS, ETC

        outl = '%s %s (%3d%% completion)' % (str(
            datetime.timedelta(seconds=int(time.time() - t))), status.__repr__(), pctdone * 100)
        # if len(outl) < maxllen:
        #    pad = maxllen - len(outl)
        #    outl += ' '*pad
        # else:
        #    maxllen = len(outl)

        if prn == True:
            print(outl)
            #sys.stderr.write(outl)
            #sys.stderr.flush()

        #test_index += 1

        # Update jobsdict
        jobsdict = get_jobs_status(jobsdict)

    now = dt_now.now()
    now_str = now.strftime('%H:%M:%S %d-%m-%Y')

    complete_str = 'completed {0} batch jobs in {1}\n{2}\n'.format(jobs_amount, str(datetime.timedelta(seconds=int(time.time() - t))),now_str)
    if prn == True:
        print(complete_str)

    # Send email when all jobs have finished:
    if email == True:
        import sys
        # Help python to find the pyemto folder
        sys.path.insert(0, "/home/hpleva/pyemto")
        from pyemto.utilities.utils import run_bash

        email_str = complete_str + "\n\n"
        for job in jobsdict:
            email_str += "{0}  {1}  {2}  {3}  {4}  {5}\n".format(jobsdict[job]['JobID'],jobsdict[job]['JobName'],jobsdict[job]['AllocTRES'],
                                                                 jobsdict[job]['Elapsed'],jobsdict[job]['State'],jobsdict[job]['ExitCode'])
        email_str += "\n"

        email_cmd = "echo \"{0}\" | mailx -s \"slurm_watchdog\" hentricks@gmail.com".format(email_str)
        run_bash(email_cmd)
        if prn == True:
            print('The following email was sent ({0})'.format(now_str))
            print(email_str)
    
    # Check for dependent commands:
    if after_run is not None:
        run_bash(after_run)
    return


if __name__ == '__main__':
    jobs = get_jobs_status()
    #for job in jobs:
    #    print(jobs[job])
    wait_for_jobs(jobs,sleeptime=300,prn=True,email=True)
